{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Images marked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mark frontal face image automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "from assist import marker\n",
    "\n",
    "marker.frontal_face_marker(r'..\\data\\woong_f.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change landmarks through dragging (if not satisfied with the auto-marking result)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker.mark_modifier(r'..\\data\\woong_f.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mark profile image manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker.manual_marker(r'..\\data\\woong_r.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start 3D fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import toml\n",
    "from core import Blendshape, contour_correspondence, EdgeTopology, fitting, LandmarkMapper, Landmark, MorphableModel, \\\n",
    "    utils, RenderingParameters, render"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and rescale pictures and landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontal_pic_name = 'woong_f'\n",
    "profile_pic_name = 'woong_r'\n",
    "frontal_img = cv2.imread(os.path.join(r'..\\data', frontal_pic_name + '.tif'))\n",
    "profile_img = cv2.imread(os.path.join(r'..\\data', profile_pic_name + '.tif'))\n",
    "width = np.shape(frontal_img)[1]\n",
    "height = np.shape(frontal_img)[0]\n",
    "\n",
    "s = 2000 / height if height >= width else 2000 / width\n",
    "scale_param = 900 / height if height >= width else 900 / width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphable_model = MorphableModel.load_model(r\"..\\py_share\\py_sfm_shape_3448.bin\")\n",
    "blendshapes = Blendshape.load_blendshapes(r\"..\\py_share\\py_expression_blendshapes_3448.bin\")\n",
    "landmark_mapper = LandmarkMapper.LandmarkMapper(r'..\\py_share\\ibug_to_sfm.txt')\n",
    "edge_topology = EdgeTopology.load_edge_topology(r'..\\py_share\\py_sfm_3448_edge_topology.json')\n",
    "contour_landmarks = contour_correspondence.ContourLandmarks()\n",
    "contour_landmarks.load(r'..\\py_share\\ibug_to_sfm.txt')\n",
    "model_contour = contour_correspondence.ModelContour()\n",
    "model_contour.load(r'..\\py_share\\sfm_model_contours.json')\n",
    "profile_landmark_mapper = LandmarkMapper.ProfileLandmarkMapper(r'..\\py_share\\profile_to_sfm.txt')\n",
    "\n",
    "frontal_landmarks = []\n",
    "landmark_ids = list(map(str, range(1, 69)))  # generates the numbers 1 to 68, as strings\n",
    "landmarks = utils.read_pts(os.path.join(r'..\\data', frontal_pic_name + '.pts'))\n",
    "for i in range(68):\n",
    "    frontal_landmarks.append(Landmark.Landmark(landmark_ids[i], [landmarks[i][0] * s, landmarks[i][1] * s]))\n",
    "\n",
    "profile_landmarks = []\n",
    "landmarks = utils.read_pts(os.path.join(r'..\\data', profile_pic_name + '.pts'))\n",
    "for x in profile_landmark_mapper.right_mapper.keys():\n",
    "    coor = landmarks[int(x) - 1]\n",
    "    profile_landmarks.append(Landmark.Landmark(x, [coor[0] * s, coor[1] * s]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_mesh, frontal_rendering_params, profile_rendering_params = fitting.fit_front_and_profile(\n",
    "    morphable_model, blendshapes, frontal_landmarks, landmark_mapper, profile_landmarks, profile_landmark_mapper,\n",
    "    round(width * s), round(height * s), edge_topology, contour_landmarks, model_contour, lambda_p=20,\n",
    "    num_iterations=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize fitting result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_img = cv2.resize(profile_img, (round(width * scale_param), round(height * scale_param)),\n",
    "                         interpolation=cv2.INTER_CUBIC)\n",
    "render.draw_wireframe_with_depth(\n",
    "    profile_img, py_mesh, profile_rendering_params.get_modelview(), profile_rendering_params.get_projection(),\n",
    "    RenderingParameters.get_opencv_viewport(width * s, height * s), profile_landmark_mapper, scale_param / s)\n",
    "\n",
    "frontal_img = cv2.resize(frontal_img, (round(width * scale_param), round(height * scale_param)),\n",
    "                         interpolation=cv2.INTER_CUBIC)\n",
    "render.draw_wireframe_with_depth(\n",
    "    frontal_img, py_mesh, frontal_rendering_params.get_modelview(), frontal_rendering_params.get_projection(),\n",
    "    RenderingParameters.get_opencv_viewport(width * s, height * s), landmark_mapper, scale_param / s)\n",
    "\n",
    "for lm in frontal_landmarks:\n",
    "    cv2.rectangle(\n",
    "        frontal_img, (int(lm.coordinates[0] * scale_param / s) - 2, int(lm.coordinates[1] * scale_param / s) - 2),\n",
    "        (int(lm.coordinates[0] * scale_param / s) + 2, int(lm.coordinates[1] * scale_param / s) + 2), (255, 0, 0))\n",
    "\n",
    "for lm in profile_landmarks:\n",
    "    cv2.rectangle(\n",
    "        profile_img, (int(lm.coordinates[0] * scale_param / s) - 2, int(lm.coordinates[1] * scale_param / s) - 2),\n",
    "        (int(lm.coordinates[0] * scale_param / s) + 2, int(lm.coordinates[1] * scale_param / s) + 2), (255, 0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show fitting result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.hstack([frontal_img, profile_img])\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save result and fitted 3D model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(frontal_pic_name + '-outcome.jpg', img)\n",
    "render.save_ply(py_mesh, frontal_pic_name + '-output', [210, 183, 108], author='Yinghao Li')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
